{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d752b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached grpcio-1.68.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in d:\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.68.1-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 keras-3.7.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f67e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\data science assighnments\\Neural networks\\Neural networks\\Alphabets_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166ec3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93759ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xbox          ybox         width       height         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc9d3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    object\n",
       "xbox       int64\n",
       "ybox       int64\n",
       "width      int64\n",
       "height     int64\n",
       "onpix      int64\n",
       "xbar       int64\n",
       "ybar       int64\n",
       "x2bar      int64\n",
       "y2bar      int64\n",
       "xybar      int64\n",
       "x2ybar     int64\n",
       "xy2bar     int64\n",
       "xedge      int64\n",
       "xedgey     int64\n",
       "yedge      int64\n",
       "yedgex     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196fda23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5955345-64ad-4176-9846-387d85dfaae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dbc0bd4-6101-46fc-aaa1-71cad121b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5713870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the image data for input into the neural network\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)  # Reshape for Conv2D layers (if using CNN)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8702e132-4ddf-4cd9-a1ec-d094683302bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, 10)  # MNIST has 10 classes (0-9)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c9353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple neural network model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28, 1)))  # Flatten the 28x28 image into a 1D vector\n",
    "model.add(Dense(128, activation='relu'))  # Fully connected layer with 128 neurons\n",
    "model.add(Dense(64, activation='relu'))   # Fully connected layer with 64 neurons\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons for digits 0-9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36019d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3421a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 0.5204 - val_accuracy: 0.9560 - val_loss: 0.1450\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9602 - loss: 0.1320 - val_accuracy: 0.9660 - val_loss: 0.1076\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9746 - loss: 0.0850 - val_accuracy: 0.9713 - val_loss: 0.0958\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9810 - loss: 0.0627 - val_accuracy: 0.9729 - val_loss: 0.0894\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0481 - val_accuracy: 0.9757 - val_loss: 0.0788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eb49ba6030>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21888b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 3ms/step - accuracy: 0.9757 - loss: 0.0788\n",
      "Test accuracy: 0.9757\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5aa0c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the first 5 test samples\n",
    "predictions = model.predict(X_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec123832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digits: [7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get the predicted classes (digits 0-9)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Predicted digits:\", predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a2169f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first 5 test samples and their predicted labels\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Pred: {predicted_classes[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e35ef-3c23-4c53-b9b3-bb2479901a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
